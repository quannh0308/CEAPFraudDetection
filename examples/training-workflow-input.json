{
  "comment": "Example input for the Training Pipeline workflow",
  "description": "This configuration is used to start a training workflow execution via Step Functions. It specifies the dataset location and data split ratios.",
  
  "executionId": "training-exec-2024-01-15-123456",
  "currentStage": "DataPrepStage",
  "previousStage": null,
  "workflowBucket": "fraud-detection-workflow-123456789012",
  
  "initialData": {
    "datasetS3Path": "s3://fraud-detection-data/kaggle-credit-card-fraud.csv",
    "outputPrefix": "s3://fraud-detection-data/prepared/",
    "trainSplit": 0.70,
    "validationSplit": 0.15,
    "testSplit": 0.15
  },
  
  "notes": {
    "datasetS3Path": "S3 path to the Kaggle Credit Card Fraud Detection dataset (284,807 transactions)",
    "outputPrefix": "S3 prefix where prepared datasets will be written (train.parquet, validation.parquet, test.parquet)",
    "trainSplit": "Proportion of data for training (0.70 = 70%)",
    "validationSplit": "Proportion of data for validation (0.15 = 15%)",
    "testSplit": "Proportion of data for testing (0.15 = 15%)",
    "executionId": "Unique identifier for this workflow execution (typically generated by Step Functions)",
    "currentStage": "Name of the first stage (DataPrepStage for training pipeline)",
    "previousStage": "null for first stage, otherwise name of previous stage",
    "workflowBucket": "S3 bucket for workflow orchestration (replace with your account-specific bucket)"
  }
}
